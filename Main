#Google Colabで実行できる形にしています
!pip install --upgrade pip
!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

!pip install transformers
!pip install datasets
!pip install fugashi
!pip install ipadic


from google.colab import drive
drive.mount('/content/drive')

# 実行前に1回はGoogle Driveをマウントすること
import os
os.chdir('/content/drive/My Drive/transformer/')
os.getcwd()

from transformers import pipeline
from transformers import BertForSequenceClassification, BertJapaneseTokenizer, Trainer, TrainingArguments
from datasets import load_dataset
import torch


# GPU使用の宣言
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#device = "cuda" if torch.cuda.is_available() else "cpu"
# ダミーデータセット
weather_dataset = load_dataset('csv', data_files={'train': 'weather_data.csv'})

# トークナイザの準備
tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')

# データセットの前処理
def tokenize_function(examples):
    return tokenizer(examples['text'], padding='max_length', truncation=True)

tokenized_weather_dataset = weather_dataset.map(tokenize_function, batched=True)

# モデルの準備
model = BertForSequenceClassification.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', num_labels=3)

# トレーニングの設定
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=8,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
)

# トレーナーの準備
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_weather_dataset['train'],
)

# トレーニングの実行
trainer.train()

# 推論用パイプラインの準備
device_number = torch.cuda.current_device() if torch.cuda.is_available() else -1
weather_classification = pipeline('text-classification', model=model, tokenizer=tokenizer, device=device_number)

#weather_classification = pipeline('text-classification', model=model, tokenizer=tokenizer, device=device)

# 入力された文章から天気を判別
print(weather_classification('今日は雨が降ったり止んだりの天気。本降りの雨になることがあります。'))
